import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import OneHotEncoder, StandardScaler
import pydeck as pdk

## Modelo de red neuronal
# Cargar el modelo
modelo = tf.keras.models.load_model("./redNeuronal/checkpoint.modelo.keras")
dataLimpia = pd.read_csv("./files/input/data.csv")


# Configuraci√≥n datos
data = pd.read_csv("./files/input/coordenadas.csv")
data['lat'] = data['lat'].str.replace(',', '.').astype(float)
data['lon'] = data['lon'].str.replace(',', '.').astype(float)

# Barra lateral
st.sidebar.title("Accidentalidad Medell√≠n")

# Opciones del men√∫

menu = st.sidebar.radio(
    "Selecciona una opci√≥n:",
    ["Presentaci√≥n", "Gr√°ficas", "Mapa", "Modelo Predictivo"]
)

# Contenido de cada opci√≥n
if menu == "Presentaci√≥n":
    st.title("An√°lisis de la Accidentalidad en Medell√≠n entre los a√±os 2015-2017üèôÔ∏èüåÑüöá")
    st.markdown("---")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""  
### **Integrantes**  
- **Jer√≥nimo Hoyos**  
- **Santiago Sosa**  
- **Brayan Cumbalaza**  
- **Manuel D. Echeverry**  
                 """)
    with col2:
        st.image("https://datosabiertos.metropol.gov.co/sites/default/files/2023-01/municipios_0.svg")

    with col3:
        st.image("https://datosabiertos.metropol.gov.co/themes/custom/theme_datosabiertos/images/logos/datos-abiertos-logo.svg",width=250)
        st.image("https://datosabiertos.metropol.gov.co/sites/default/files/2022-12/futuro-sostenible-logo.svg",width=230)

    st.markdown("""
---

## **Introducci√≥n**  
En este trabajo final realizaremos un an√°lisis del conjunto de datos [Accidentalidad Valle de Aburr√°](https://datosabiertos.metropol.gov.co/dataset/f2c142b3-b5c1-4c62-9902-797f04aee252), obtenido del banco de datos abiertos del **√Årea Metropolitana del Valle de Aburr√°**.

Este dataset contiene informaci√≥n sobre los accidentes registrados por las Secretar√≠as de Movilidad y Transporte durante los a√±os **2015**, **2016**, **2017** y **2018** en algunos municipios del Valle de Aburr√°.  

---

## **Descripci√≥n del Dataset**  
El conjunto de datos est√° compuesto por **11 columnas**:  

- üìç **`cod_municipio`**: C√≥digo del municipio.  
- üèôÔ∏è **`municipio`**: Nombre del municipio.  
- üìÖ **`fecha`**: Fecha del evento o suceso.  
- üïí **`hora`**: Hora del evento o suceso.  
- üìÜ **`dia_semana`**: D√≠a de la semana.  
- üö® **`clase`**: Tipo o categor√≠a del evento.  
- üìå **`direccion`**: Direcci√≥n del lugar del evento.  
- ‚ö†Ô∏è **`gravedad_asociada`**: Nivel de gravedad asociado.  
- üè° **`barrio`**: Nombre del barrio.  
- üî¢ **`comuna`**: N√∫mero o nombre de la comuna.  
- üõ£Ô∏è **`diseno`**: Dise√±o asociado al evento o suceso.  

---

## **Objetivo del An√°lisis**  
Este an√°lisis tiene como objetivo identificar patrones y factores de riesgo en la accidentalidad, con el fin de proveer informaci√≥n para generar soluciones efectivas basadas en los hallazgos obtenidos. Para ello, se emplear√°n diversas herramientas visuales como gr√°ficas de calor, gr√°ficos de barras y mapas interactivos, utilizando herramientas como Streamlit, Google Maps, Pandas, Seaborn y NumPy.  
""")

elif menu == "Gr√°ficas":

    # Mostrar la gr√°fica en Streamlit
    st.title("An√°lisis descriptivoüìäüìà")
    st.markdown("---")
    st.image("dashboard/figures/horas.png")
    st.markdown("---")
    st.image("dashboard/figures/semana.png")
    st.markdown("---")
    st.image("dashboard/figures/mes.png")
    st.markdown("---")
    st.image("dashboard/figures/agosto.png")






elif menu == "Mapa":

    # Configuraci√≥n de los hexagonos
    st.title("Los 100 lugares de Medell√≠n con m√°s accidentes üó∫Ô∏èüìå")
    st.markdown("---")
    hexagonos = pdk.Layer(
    "HexagonLayer",
    data=data,
    get_position=["lon", "lat"],
    get_elevation="num_accidentes", 
    radius=50,
    elevation_scale=5, #Diferencia escala 
    elevation_range=[10, 350], #L√≠mites 
    extruded=True, #Volumen
    )

    # Configuraci√≥n de la vista inicial
    view_state = pdk.ViewState(
    latitude=data['lat'].mean(), #Centrar posici√≥n
    longitude=data['lon'].mean(), 
    zoom=12,
    pitch=50, #Inclinaci√≥n
    )

    # Mostrar el mapa
    st.pydeck_chart(pdk.Deck(layers=[hexagonos], initial_view_state=view_state))

    # Mostrar tabla
    st.markdown("---")
    st.subheader("Direcciones √∫nicas con m√°s accidentes")
    
    st.dataframe(data)

elif menu == "Modelo Predictivo":
    # Variables utilizadas
    features = ["CLASE", "D√çA DE LA SEMANA", "MES", "HORA24", "DISE√ëO", "COMUNA"]

    # Inicializar transformaciones con los mismos par√°metros usados en entrenamiento
    encoder = OneHotEncoder(drop="first", sparse_output=False)
    encoder.fit(dataLimpia[["CLASE", "D√çA DE LA SEMANA", "MES", "DISE√ëO", "COMUNA"]])

    scaler = StandardScaler()
    scaler.fit(dataLimpia[["HORA24"]])

    st.title("Modelo Predictivo de Accidentes de la gravedad del accidenteüß†")
    st.markdown("---")
    clase = st.selectbox(
        "Seleccione la clase de accidente", dataLimpia["CLASE"].unique()
    )
    dia_semana = st.selectbox(
        "Seleccione el d√≠a de la semana", dataLimpia["D√çA DE LA SEMANA"].unique()
    )
    mes = st.selectbox("Seleccione el mes", dataLimpia["MES"].unique())
    hora24 = st.selectbox(
        "Seleccione la hora (24h)", sorted(dataLimpia["HORA24"].unique())
    )
    diseno = st.selectbox("Seleccione el dise√±o", dataLimpia["DISE√ëO"].unique())
    comuna = st.selectbox("Seleccione la comuna", dataLimpia["COMUNA"].unique())

    # Convertir entrada del usuario a DataFrame
    entrada_df = pd.DataFrame([[clase, dia_semana, mes, hora24, diseno, comuna]], 
                            columns=["CLASE", "D√çA DE LA SEMANA", "MES", "HORA24", "DISE√ëO", "COMUNA"])

    # Aplicar transformaciones
    entrada_encoded = encoder.transform(entrada_df[["CLASE", "D√çA DE LA SEMANA", "MES", "DISE√ëO", "COMUNA"]])
    entrada_scaled = scaler.transform(entrada_df[["HORA24"]])

    # Unir las caracter√≠sticas transformadas
    entrada_final = np.hstack((entrada_encoded, entrada_scaled)).astype(np.float32)

    # Predicci√≥n
    if st.button("Predecir"):
        prediccion = modelo.predict(entrada_final)
        clase_predicha = np.argmax(prediccion)  # Obtener la clase m√°s probable
        
        # Diccionario para interpretar la salida
        clases_dict = {0: "Da√±os materiales", 1: "Heridos", 2: "Muertos"}
        
        st.subheader("Resultado de la Predicci√≥n:")
        st.write(f"‚ö†Ô∏è **Categor√≠a predicha:** {clases_dict[clase_predicha]}")

        st.subheader("Probabilidades por clase:")
        for i, prob in enumerate(prediccion[0]):
            st.write(f"üìå **{clases_dict[i]}**: {prob:.2%}")


st.sidebar.write("---")
st.sidebar.write("Talento Tech")
st.sidebar.write("Universidad Nacional de Colombia")
st.sidebar.write("Sede Medell√≠n")

st.markdown("---")

col1, col2 = st.columns([1, 2]) 
with col1:
    st.link_button("Repositorio", "https://github.com/BrayanCumbalazaVallejo/Project_BootCamp")
    st.image("https://img.icons8.com/?size=100&id=Mhl1TfJLdkh5&format=png&color=000000",width=110)
with col2:
    st.image("https://lh4.googleusercontent.com/proxy/WNtyuTbDjnnITJFxg1dlI63L0jfIMRf0CIKg75VavFd3ameUuokpEiXIZvafO0UbA3rGKkhjDZ2HFtRWcGiPIn7Syd37PqnCrQuXFNHguRRPYm__safRJi9Q",width=400)
